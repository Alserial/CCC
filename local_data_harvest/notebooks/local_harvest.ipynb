{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from environment import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### local air quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_health_advice(value):\n",
    "    if value < 40:\n",
    "        return \"Good\"\n",
    "    elif 40 <= value < 80:\n",
    "        return \"Fair\"\n",
    "    elif 80 <= value < 120:\n",
    "        return \"Poor\"\n",
    "    elif 120 <= value < 300:\n",
    "        return \"Very poor\"\n",
    "    else:\n",
    "        return \"Extremely poor\"\n",
    "\n",
    "def euler_dist(x1, y1, x2, y2):\n",
    "    return np.sqrt((x1 - x2)**2 + (y1 - y2)**2)\n",
    "    \n",
    "\n",
    "def find_sa2(lon, lat):\n",
    "    with open(\"../data/All_SA2.json\", 'r') as f:\n",
    "        data = json.load(f)\n",
    "        \n",
    "    min_dist = float('inf')\n",
    "    sa2_code = None\n",
    "    sa2_name = None\n",
    "    for lst in data:\n",
    "        dist = euler_dist(lon, lat, lst['lon'], lst['lat'])\n",
    "        if dist < min_dist:\n",
    "            min_dist = dist\n",
    "            sa2_code = lst['sa2_code']\n",
    "            sa2_name = lst['sa2_name']\n",
    "    return sa2_code, sa2_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "harvested = {}    \n",
    "User_Agent = 'curl/8.4.0'\n",
    "\n",
    "vic_url = \"https://gateway.api.epa.vic.gov.au/environmentMonitoring/v1/sites\"\n",
    "params = {\"environmentalSegment\": \"air\"}\n",
    "headers = {'User-Agent': User_Agent,\n",
    "            'Cache-Control': 'no-cache',\n",
    "            'X-API-key': \"96527bc2db05455097a52c8e89fa55dc\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(vic_url, params=params, headers=headers, timeout = 60)\n",
    "if response.status_code == 200:        \n",
    "    data_mel = response.json()\n",
    "    \n",
    "records = data_mel.get('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    merged_data = []\n",
    "    response = requests.get(vic_url, params=params, headers=headers, timeout = 60)\n",
    "    print(response.status_code)\n",
    "    if response.status_code == 200:        \n",
    "        data_mel = response.json()\n",
    "        for row in data_mel.get('records'):\n",
    "            site_health_advices = row.get('siteHealthAdvices')\n",
    "            # make sure that there is details for air quality \n",
    "            if site_health_advices is not None and isinstance(site_health_advices, list) and len(site_health_advices) > 0:\n",
    "                air_detail = site_health_advices[0]\n",
    "                lat = row.get(\"geometry\").get('coordinates')[0]\n",
    "                lon = row.get(\"geometry\").get('coordinates')[1]\n",
    "                sa2_code, sa2_name = find_sa2(lon, lat)\n",
    "                observation_data = {\n",
    "                    \"siteName\": row.get(\"siteName\"),\n",
    "                    \"Longitude\": lon,\n",
    "                    \"Latitude\": lat,\n",
    "                    \"SA2_Code\": sa2_code,\n",
    "                    \"SA2_Name\": sa2_name,\n",
    "                    \"Date\": air_detail.get(\"until\")[:10],\n",
    "                    \"ParameterCode\": air_detail.get(\"healthParameter\"),\n",
    "                    \"Value\": air_detail.get(\"averageValue\"),\n",
    "                    \"HealthAdvice\" : air_detail.get(\"healthAdvice\")\n",
    "                }\n",
    "                merged_data.append(observation_data)\n",
    "                \n",
    "    site_details_url = \"https://data.airquality.nsw.gov.au/api/Data/get_SiteDetails\"\n",
    "    site_details_response = requests.get(site_details_url, headers={\"accept\": \"application/json\"})\n",
    "    site_details_data = site_details_response.json()\n",
    "\n",
    "    # link the site id with the site name and its location\n",
    "    site_id_to_details = {site[\"Site_Id\"]: {\"SiteName\": site[\"SiteName\"], \"Longitude\": site[\"Longitude\"], \"Latitude\": site[\"Latitude\"]} for site in site_details_data}\n",
    "    # calcualte the time\n",
    "    current_date = datetime.now()\n",
    "    previous_date = current_date - timedelta(days=1)\n",
    "    previous_date = previous_date.strftime(\"%Y-%m-%d\")\n",
    "    current_date = current_date.strftime(\"%Y-%m-%d\")\n",
    "    # get the observation information\n",
    "    observations_url = \"https://data.airquality.nsw.gov.au/api/Data/get_Observations\"\n",
    "    headers = {\"accept\": \"application/json\", \"Content-Type\": \"application/json\"}\n",
    "    data = {\n",
    "        \"Parameters\": [\"PM10\"],\n",
    "        \"Sites\": list(site_id_to_details.keys()),\n",
    "        \"StartDate\": previous_date,\n",
    "        \"EndDate\": current_date,\n",
    "        \"Categories\": [\"Averages\"],\n",
    "        \"SubCategories\": [\"Hourly\"],\n",
    "        \"Frequency\": [\"24h rolling average derived from 1h average\"]\n",
    "        }\n",
    "    observations_response = requests.post(observations_url, headers=headers, json=data)\n",
    "    observations_data = observations_response.json()\n",
    "    for observation in observations_data:\n",
    "        site_id = observation[\"Site_Id\"]\n",
    "        site_details = site_id_to_details.get(site_id, {})\n",
    "        lat = site_details.get(\"Latitude\")\n",
    "        lon = site_details.get(\"Longitude\")\n",
    "        sa2_code, sa2_name = find_sa2(lon, lat)\n",
    "        site_id = observation[\"Site_Id\"]\n",
    "        site_details = site_id_to_details.get(site_id, {})\n",
    "        if observation[\"Value\"]:\n",
    "            observation_data = {\n",
    "                \"siteName\": site_details.get(\"SiteName\"),\n",
    "                \"Longitude\": lon,\n",
    "                \"Latitude\": lat,\n",
    "                \"SA2_Code\": sa2_code,\n",
    "                \"SA2_Name\": sa2_name,\n",
    "                \"Date\": observation[\"Date\"],\n",
    "                \"ParameterCode\": observation[\"Parameter\"][\"ParameterCode\"],\n",
    "                \"Value\": observation[\"Value\"],\n",
    "                \"HealthAdvice\" : determine_health_advice(observation[\"Value\"])\n",
    "            }\n",
    "            merged_data.append(observation_data)\n",
    "            \n",
    "except requests.exceptions.Timeout:\n",
    "    print()\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(e)\n",
    "with open(\"../data/air_quality_demo.json\", 'w') as f:\n",
    "    json.dump(merged_data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### local weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Harvest weather data from BOM, and write the data into Elastic Search\n",
    "       the script is called every 72hrs, matching the frequency of update of the website\n",
    "    \"\"\"\n",
    "    with open(\"../data/weather_APIs.json\", 'r') as f:\n",
    "        site_apis = json.load(f)\n",
    "        \n",
    "    with open(\"../data/site_sa2.json\") as f:\n",
    "        site_sa2 = json.load(f)\n",
    "    \n",
    "    all_data = []\n",
    "    for site, url in site_apis.items(): \n",
    "        try:\n",
    "            response = requests.get(url, timeout=60)\n",
    "            if response.status_code == 200:\n",
    "                \n",
    "                data = response.json()\n",
    "                sa2_code = None\n",
    "                sa2_name = None\n",
    "                lon, lat = (0, 0)\n",
    "                for dic in site_sa2:\n",
    "                    if dic['site'] == site:\n",
    "                        sa2_code = dic['sa2_code']\n",
    "                        sa2_name = dic['sa2_name']\n",
    "                        lon, lat = dic['location']\n",
    "                        \n",
    "                cleaned_data = []\n",
    "                for observation in data[\"observations\"][\"data\"]:\n",
    "                    cleaned_observation = {\n",
    "                        \"name\": observation.get(\"name\", \"\"),\n",
    "                        \"local_date_time_full\": observation.get(\"local_date_time_full\", \"\"),\n",
    "                        \"Longitude\": lon,\n",
    "                        \"Latitude\": lat,\n",
    "                        \"SA2_Code\": sa2_code,\n",
    "                        \"SA2_Name\": sa2_name,\n",
    "                        \"gust_kmh\": observation.get(\"gust_kmh\", \"\"),\n",
    "                        \"apparent_t\": observation.get(\"apparent_t\"),\n",
    "                        \"delta_t\": observation.get(\"delta_t\", \"\"),\n",
    "                        \"air_temp\": observation.get(\"air_temp\", \"\"),\n",
    "                        \"press\": observation.get(\"press\", \"\"),\n",
    "                        \"rain_trace\": observation.get(\"rain_trace\",\"\"),\n",
    "                        \"rel_hum\": observation.get(\"rel_hum\", \"\"), \n",
    "                        \"vis_km\": observation.get(\"vis_km\", \"\"), \n",
    "                        \"wind_spd_kmh\": observation.get(\"wind_spd_kmh\", \"\")\n",
    "                    }\n",
    "                    cleaned_data.append(cleaned_observation)\n",
    "                all_data.append(cleaned_data) \n",
    "            else:\n",
    "                return response.status_code\n",
    "        except requests.exceptions.Timeout:\n",
    "            print()\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(e)\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = main()\n",
    "with open(\"../data/weather_demo.json\", 'w') as f:\n",
    "    json.dump(data, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill data for empty SA2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/weather_demo.json\", 'r') as f:\n",
    "    data = json.load(f)\n",
    "with open(\"../data/All_SA2.json\", 'r') as f:\n",
    "    all_sa2 = json.load(f)    \n",
    "data\n",
    "\n",
    "with open(\"../data/air_quality_demo.json\", 'r') as f:\n",
    "    air = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13248"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = 0\n",
    "for ins in data:\n",
    "    total+=len(ins)\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "seen = []\n",
    "test = []\n",
    "for inst in data:\n",
    "    seen.append(inst[0]['SA2_Code'])\n",
    "    test.append(len(inst))\n",
    "seen = list(set(seen))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
